{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CS 520: Exercise 1  \n",
        "Author: Ben Wei  \n",
        "\n",
        "For this exercise, I chose to use Gemini and ChatGPT. This code uses API keys to access the LLMs. Because this code must be uploaded to Github and I'd like my keys to remain private, you must supply your own for this code to run. Of course, the results are also posted separately in the repository."
      ],
      "metadata": {
        "id": "JY3hatb0RnDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Initialization\n",
        "\n",
        "import os\n",
        "\n",
        "# Paste your Gemini API Key here\n",
        "os.environ['GEMINI_API_KEY'] = 'YOUR-KEY-HERE'\n",
        "\n",
        "# Paste your ChatGPT API Key here\n",
        "OPENAI_KEY = \"YOUR-KEY-HERE\"\n",
        "\n",
        "# Load the dataset\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"evalplus/humanevalplus\")\n",
        "\n",
        "# Initialize LLM APIs\n",
        "from google import genai\n",
        "from openai import OpenAI\n",
        "\n",
        "client = genai.Client()\n",
        "GPT_client = OpenAI(api_key=OPENAI_KEY)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OI-47yofRrEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Generate responses for each prompt from each model\n",
        "responses = []\n",
        "GPT_responses = []\n",
        "k = 2\n",
        "offset = 40\n",
        "\n",
        "# Use Self-Planning and Self-Edit\n",
        "prefix0 = \"Please solve the following coding problem and format your code with markdown.\\n\"\n",
        "\n",
        "prefix1 = \"For the following functions, write numbered steps before implementing them.\\n\\n\"\n",
        "prefix2 = \"After writing the code, check for errors and fix them if found.\\n\\n\"\n",
        "\n",
        "prefixes = [prefix1, prefix2]\n",
        "\n",
        "for i in range(10):\n",
        "  responses.insert(i, [])\n",
        "  GPT_responses.insert(i, [])\n",
        "  for j in range(k):\n",
        "    # Prompt Gemini\n",
        "    response = client.models.generate_content(\n",
        "      model=\"gemini-2.0-flash\",\n",
        "      contents=prefix0+prefixes[j]+dataset[\"test\"][i+offset][\"prompt\"]\n",
        "    )\n",
        "    responses[i].insert(j, response.text)\n",
        "\n",
        "    # Prompt GPT\n",
        "    gpt_response = GPT_client.responses.create(\n",
        "        model=\"gpt-4\",\n",
        "        input=prefix0+prefixes[j]+dataset[\"test\"][i+offset][\"prompt\"]\n",
        "    )\n",
        "    GPT_responses[i].insert(j, gpt_response.output_text)"
      ],
      "metadata": {
        "id": "m0aukATGoviy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Test responses for each prompt\n",
        "import re\n",
        "\n",
        "results = []\n",
        "GPT_results = []\n",
        "\n",
        "for i in range(10):\n",
        "  results.insert(i, [])\n",
        "  GPT_results.insert(i, [])\n",
        "  for j in range(k):\n",
        "    # Evaluate Gemini Responses\n",
        "    ns = {}\n",
        "    result = True\n",
        "    try:\n",
        "      match = re.search(r\"```python(.*?)```\", responses[i][j], re.DOTALL)\n",
        "      code = match.group(1)\n",
        "      exec(code, ns)\n",
        "      exec(dataset[\"test\"][i+offset][\"test\"], ns)\n",
        "      exec(\"check(\"+dataset[\"test\"][i+offset][\"entry_point\"]+\")\", ns);\n",
        "    except Exception as e:\n",
        "      result = False\n",
        "    results[i].insert(j, result)\n",
        "\n",
        "    #Evaluate ChatGPT Responses\n",
        "    ns2 = {}\n",
        "    result = True\n",
        "    try:\n",
        "      match = re.search(r\"```python(.*?)```\", GPT_responses[i][j], re.DOTALL)\n",
        "      gpt_code = match.group(1)\n",
        "      exec(gpt_code, ns2)\n",
        "      exec(dataset[\"test\"][i+offset][\"test\"], ns2)\n",
        "      exec(\"check(\"+dataset[\"test\"][i+offset][\"entry_point\"]+\")\", ns2);\n",
        "    except Exception as e:\n",
        "      result = False\n",
        "    GPT_results[i].insert(j, result)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-O6hv3Xb1hKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Results\n",
        "print(results)\n",
        "print(GPT_results)"
      ],
      "metadata": {
        "id": "sk2NclIZDeJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Print Prompts\n",
        "for i in range(10):\n",
        "  for j in range(k):\n",
        "    print(prefix0+prefixes[j]+dataset[\"test\"][i+offset][\"prompt\"])"
      ],
      "metadata": {
        "id": "89LjS09mxMGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Print Responses\n",
        "for i in range(10):\n",
        "  for j in range(k):\n",
        "    print(responses[i][j])\n",
        "    print(GPT_responses[i][j])"
      ],
      "metadata": {
        "id": "U0DXirNoBoxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis of HumanEval/46\n",
        "import traceback\n",
        "\n",
        "#print(dataset[\"test\"][46][\"prompt\"])\n",
        "#print(dataset[\"test\"][46][\"test\"])\n",
        "\n",
        "#print(responses[46-offset][0])\n",
        "#print(responses[46-offset][1])\n",
        "#print(GPT_responses[46-offset][0])\n",
        "#print(GPT_responses[46-offset][1])"
      ],
      "metadata": {
        "id": "YsP2KjmDF31e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Results of HumanEval 46 without typo\n",
        "\n",
        "prompt = '''def fib4(n: int):\n",
        "    \"\"\"The Fib4 number sequence is a sequence similar to the Fibbonacci sequence that's defined as follows:\n",
        "    fib4(0) -> 0\n",
        "    fib4(1) -> 0\n",
        "    fib4(2) -> 2\n",
        "    fib4(3) -> 0\n",
        "    fib4(n) -> fib4(n-1) + fib4(n-2) + fib4(n-3) + fib4(n-4).\n",
        "    Please write a function to efficiently compute the n-th element of the fib4 number sequence.  Do not use recursion.\n",
        "    >>> fib4(5)\n",
        "    4\n",
        "    >>> fib4(6)\n",
        "    8\n",
        "    >>> fib4(7)\n",
        "    14\n",
        "    \"\"\"\n",
        "'''\n",
        "\n",
        "new46_responses = []\n",
        "new46_gpt_responses = []\n",
        "\n",
        "for j in range(k):\n",
        "  # Prompt Gemini\n",
        "  response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=prefix0+prefixes[j]+prompt\n",
        "  )\n",
        "  new46_responses.insert(j, response.text)\n",
        "\n",
        "  # Prompt GPT\n",
        "  gpt_response = GPT_client.responses.create(\n",
        "      model=\"gpt-4\",\n",
        "      input=prefix0+prefixes[j]+prompt\n",
        "  )\n",
        "  new46_gpt_responses.insert(j, gpt_response.output_text)\n",
        "\n",
        "new46_results = []\n",
        "new46_gpt_results = []\n",
        "\n",
        "for j in range(k):\n",
        "    # Evaluate Gemini Responses\n",
        "    ns = {}\n",
        "    result = True\n",
        "    try:\n",
        "      match = re.search(r\"```python(.*?)```\", new46_responses[j], re.DOTALL)\n",
        "      code = match.group(1)\n",
        "      exec(code, ns)\n",
        "      exec(dataset[\"test\"][46][\"test\"], ns)\n",
        "      exec(\"check(\"+dataset[\"test\"][46][\"entry_point\"]+\")\", ns);\n",
        "    except Exception as e:\n",
        "      result = False\n",
        "    new46_results.insert(j, result)\n",
        "\n",
        "    #Evaluate ChatGPT Responses\n",
        "    ns2 = {}\n",
        "    result = True\n",
        "    try:\n",
        "      match = re.search(r\"```python(.*?)```\", new46_gpt_responses[j], re.DOTALL)\n",
        "      gpt_code = match.group(1)\n",
        "      exec(gpt_code, ns2)\n",
        "      exec(dataset[\"test\"][46][\"test\"], ns2)\n",
        "      exec(\"check(\"+dataset[\"test\"][46][\"entry_point\"]+\")\", ns2);\n",
        "    except Exception as e:\n",
        "      result = False\n",
        "    new46_gpt_results.insert(j, result)\n",
        "\n",
        "print(new46_results)\n",
        "print(new46_gpt_results)"
      ],
      "metadata": {
        "id": "3J6Q6fDPWRa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis of HumanEval/48\n",
        "import traceback\n",
        "\n",
        "print(dataset[\"test\"][48][\"prompt\"])\n",
        "#print(dataset[\"test\"][48][\"test\"])\n",
        "\n",
        "#print(responses[48-offset][0])\n",
        "#print(responses[48-offset][1])\n",
        "#print(GPT_responses[48-offset][0])\n",
        "#print(GPT_responses[48-offset][1])"
      ],
      "metadata": {
        "id": "k-9Xr9MAr-1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Results of HumanEval 48 when adding 'Consider all possible inputs.'\n",
        "\n",
        "prompt = '''def is_palindrome(text: str):\n",
        "    \"\"\"\n",
        "    Checks if given string is a palindrome\n",
        "    >>> is_palindrome('')\n",
        "    True\n",
        "    >>> is_palindrome('aba')\n",
        "    True\n",
        "    >>> is_palindrome('aaaaa')\n",
        "    True\n",
        "    >>> is_palindrome('zbcd')\n",
        "    False\n",
        "    \"\"\"\n",
        "'''\n",
        "\n",
        "newprefix = \"Consider whitespace when evaluating palindromes.\\n\"\n",
        "\n",
        "new48_responses = []\n",
        "new48_gpt_responses = []\n",
        "\n",
        "for j in range(k):\n",
        "  # Prompt Gemini\n",
        "  response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=prefix0+prefixes[j]+newprefix+prompt\n",
        "  )\n",
        "  new48_responses.insert(j, response.text)\n",
        "\n",
        "  # Prompt GPT\n",
        "  gpt_response = GPT_client.responses.create(\n",
        "      model=\"gpt-4\",\n",
        "      input=prefix0+prefixes[j]+newprefix+prompt\n",
        "  )\n",
        "  new48_gpt_responses.insert(j, gpt_response.output_text)\n",
        "\n",
        "new48_results = []\n",
        "new48_gpt_results = []\n",
        "\n",
        "for j in range(k):\n",
        "    # Evaluate Gemini Responses\n",
        "    ns = {}\n",
        "    result = True\n",
        "    try:\n",
        "      match = re.search(r\"```python(.*?)```\", new48_responses[j], re.DOTALL)\n",
        "      code = match.group(1)\n",
        "      exec(code, ns)\n",
        "      exec(dataset[\"test\"][48][\"test\"], ns)\n",
        "      exec(\"check(\"+dataset[\"test\"][48][\"entry_point\"]+\")\", ns);\n",
        "    except Exception as e:\n",
        "      result = False\n",
        "    new48_results.insert(j, result)\n",
        "\n",
        "    #Evaluate ChatGPT Responses\n",
        "    ns2 = {}\n",
        "    result = True\n",
        "    try:\n",
        "      match = re.search(r\"```python(.*?)```\", new48_gpt_responses[j], re.DOTALL)\n",
        "      gpt_code = match.group(1)\n",
        "      exec(gpt_code, ns2)\n",
        "      exec(dataset[\"test\"][48][\"test\"], ns2)\n",
        "      exec(\"check(\"+dataset[\"test\"][48][\"entry_point\"]+\")\", ns2);\n",
        "    except Exception as e:\n",
        "      result = False\n",
        "    new48_gpt_results.insert(j, result)\n",
        "\n",
        "print(new48_results)\n",
        "print(new48_gpt_results)"
      ],
      "metadata": {
        "id": "dXWbrqPLuzg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Innovation / Experimentation\n",
        "\n",
        "## Generate responses for each prompt from each model\n",
        "responses = []\n",
        "GPT_responses = []\n",
        "k = 2\n",
        "offset = 40\n",
        "\n",
        "# Use Self-Planning and Self-Edit\n",
        "prefix0 = \"You are an Expert Python Programmer.\\nPlease solve the following coding problem and format your code with markdown.\\n\"\n",
        "\n",
        "prefix1 = \"For the following functions, write numbered steps before implementing them.\\n\\n\"\n",
        "prefix2 = \"After writing the code, check for errors and fix them if found.\\n\\n\"\n",
        "\n",
        "prefixes = [prefix1, prefix2]\n",
        "\n",
        "for i in range(10):\n",
        "  responses.insert(i, [])\n",
        "  GPT_responses.insert(i, [])\n",
        "  for j in range(k):\n",
        "    # Prompt Gemini\n",
        "    response = client.models.generate_content(\n",
        "      model=\"gemini-2.0-flash\",\n",
        "      contents=prefix0+prefixes[j]+dataset[\"test\"][i+offset][\"prompt\"]\n",
        "    )\n",
        "    responses[i].insert(j, response.text)\n",
        "\n",
        "    # Prompt GPT\n",
        "    gpt_response = GPT_client.responses.create(\n",
        "        model=\"gpt-4\",\n",
        "        input=prefix0+prefixes[j]+dataset[\"test\"][i+offset][\"prompt\"]\n",
        "    )\n",
        "    GPT_responses[i].insert(j, gpt_response.output_text)\n",
        "\n",
        "## Test responses for each prompt\n",
        "import re\n",
        "\n",
        "results = []\n",
        "GPT_results = []\n",
        "\n",
        "for i in range(10):\n",
        "  results.insert(i, [])\n",
        "  GPT_results.insert(i, [])\n",
        "  for j in range(k):\n",
        "    # Evaluate Gemini Responses\n",
        "    ns = {}\n",
        "    result = True\n",
        "    try:\n",
        "      match = re.search(r\"```python(.*?)```\", responses[i][j], re.DOTALL)\n",
        "      code = match.group(1)\n",
        "      exec(code, ns)\n",
        "      exec(dataset[\"test\"][i+offset][\"test\"], ns)\n",
        "      exec(\"check(\"+dataset[\"test\"][i+offset][\"entry_point\"]+\")\", ns);\n",
        "    except Exception as e:\n",
        "      result = False\n",
        "    results[i].insert(j, result)\n",
        "\n",
        "    #Evaluate ChatGPT Responses\n",
        "    ns2 = {}\n",
        "    result = True\n",
        "    try:\n",
        "      match = re.search(r\"```python(.*?)```\", GPT_responses[i][j], re.DOTALL)\n",
        "      gpt_code = match.group(1)\n",
        "      exec(gpt_code, ns2)\n",
        "      exec(dataset[\"test\"][i+offset][\"test\"], ns2)\n",
        "      exec(\"check(\"+dataset[\"test\"][i+offset][\"entry_point\"]+\")\", ns2);\n",
        "    except Exception as e:\n",
        "      result = False\n",
        "    GPT_results[i].insert(j, result)\n",
        "\n",
        "# Print Results\n",
        "print(results)\n",
        "print(GPT_results)\n"
      ],
      "metadata": {
        "id": "BHu3stsQ1c_g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}